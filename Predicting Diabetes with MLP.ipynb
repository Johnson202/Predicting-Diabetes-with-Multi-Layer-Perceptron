{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41604d77",
   "metadata": {},
   "source": [
    "## Import Libraries/UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32aa72fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jonathon\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_cleansing_and_exploration import read_csv, check_null_values, count_zeros, correlation\n",
    "from data_preparation import replace, filling, split\n",
    "from MLP_modeling import split2, train_model, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25afa537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976802cc",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a33face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2      138             62             35        0  33.6   \n",
       "1               0       84             82             31      125  38.2   \n",
       "2               0      145              0              0        0  44.2   \n",
       "3               0      135             68             42      250  42.3   \n",
       "4               1      139             62             41      480  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2       75             64             24       55  29.7   \n",
       "1996            8      179             72             42      130  32.7   \n",
       "1997            6       85             78              0        0  31.2   \n",
       "1998            0      129            110             46      130  67.1   \n",
       "1999            2       81             72             15       76  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb591515",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856eb7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = check_null_values()\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a256e19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pregnancies': 301,\n",
       " 'Glucose': 13,\n",
       " 'BloodPressure': 90,\n",
       " 'SkinThickness': 573,\n",
       " 'Insulin': 956,\n",
       " 'BMI': 28,\n",
       " 'DiabetesPedigreeFunction': 0,\n",
       " 'Age': 0,\n",
       " 'Outcome': 1316}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_zeros = count_zeros()\n",
    "num_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937431c",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74c9c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies  Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                      1.00     0.12           0.15          -0.06   \n",
       "Glucose                          0.12     1.00           0.14           0.06   \n",
       "BloodPressure                    0.15     0.14           1.00           0.20   \n",
       "SkinThickness                   -0.06     0.06           0.20           1.00   \n",
       "Insulin                         -0.08     0.32           0.09           0.45   \n",
       "BMI                              0.02     0.23           0.28           0.39   \n",
       "DiabetesPedigreeFunction        -0.03     0.12           0.05           0.18   \n",
       "Age                              0.54     0.25           0.24          -0.11   \n",
       "Outcome                          0.22     0.46           0.08           0.08   \n",
       "\n",
       "                          Insulin   BMI  DiabetesPedigreeFunction   Age  \\\n",
       "Pregnancies                 -0.08  0.02                     -0.03  0.54   \n",
       "Glucose                      0.32  0.23                      0.12  0.25   \n",
       "BloodPressure                0.09  0.28                      0.05  0.24   \n",
       "SkinThickness                0.45  0.39                      0.18 -0.11   \n",
       "Insulin                      1.00  0.22                      0.19 -0.09   \n",
       "BMI                          0.22  1.00                      0.13  0.04   \n",
       "DiabetesPedigreeFunction     0.19  0.13                      1.00  0.03   \n",
       "Age                         -0.09  0.04                      0.03  1.00   \n",
       "Outcome                      0.12  0.28                      0.16  0.24   \n",
       "\n",
       "                          Outcome  \n",
       "Pregnancies                  0.22  \n",
       "Glucose                      0.46  \n",
       "BloodPressure                0.08  \n",
       "SkinThickness                0.08  \n",
       "Insulin                      0.12  \n",
       "BMI                          0.28  \n",
       "DiabetesPedigreeFunction     0.16  \n",
       "Age                          0.24  \n",
       "Outcome                      1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = correlation()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f5eb0",
   "metadata": {},
   "source": [
    "## Data Preparation (for modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24a5a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   1987 non-null   float64\n",
      " 2   BloodPressure             1910 non-null   float64\n",
      " 3   SkinThickness             1427 non-null   float64\n",
      " 4   Insulin                   1044 non-null   float64\n",
      " 5   BMI                       1972 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_zero_to_nan = replace()\n",
    "df_zero_to_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d38523be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2    138.0           62.0           35.0      NaN  33.6   \n",
       "1               0     84.0           82.0           31.0    125.0  38.2   \n",
       "2               0    145.0            NaN            NaN      NaN  44.2   \n",
       "3               0    135.0           68.0           42.0    250.0  42.3   \n",
       "4               1    139.0           62.0           41.0    480.0  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2     75.0           64.0           24.0     55.0  29.7   \n",
       "1996            8    179.0           72.0           42.0    130.0  32.7   \n",
       "1997            6     85.0           78.0            NaN      NaN  31.2   \n",
       "1998            0    129.0          110.0           46.0    130.0  67.1   \n",
       "1999            2     81.0           72.0           15.0     76.0  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zero_to_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e71b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   2000 non-null   float64\n",
      " 2   BloodPressure             2000 non-null   float64\n",
      " 3   SkinThickness             2000 non-null   float64\n",
      " 4   Insulin                   2000 non-null   float64\n",
      " 5   BMI                       2000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_nan_to_avg = filling()\n",
    "df_nan_to_avg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b400a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>153.74</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>72.4</td>\n",
       "      <td>29.34</td>\n",
       "      <td>153.74</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>480.00</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.34</td>\n",
       "      <td>153.74</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2    138.0           62.0          35.00   153.74  33.6   \n",
       "1               0     84.0           82.0          31.00   125.00  38.2   \n",
       "2               0    145.0           72.4          29.34   153.74  44.2   \n",
       "3               0    135.0           68.0          42.00   250.00  42.3   \n",
       "4               1    139.0           62.0          41.00   480.00  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2     75.0           64.0          24.00    55.00  29.7   \n",
       "1996            8    179.0           72.0          42.00   130.00  32.7   \n",
       "1997            6     85.0           78.0          29.34   153.74  31.2   \n",
       "1998            0    129.0          110.0          46.00   130.00  67.1   \n",
       "1999            2     81.0           72.0          15.00    76.00  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan_to_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42465cf9",
   "metadata": {},
   "source": [
    "### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2debb40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       " 333            12    106.0           80.0          29.34   153.74  23.6   \n",
       " 721             1    114.0           66.0          36.00   200.00  38.1   \n",
       " 1352            8     85.0           55.0          20.00   153.74  24.4   \n",
       " 1680            1    181.0           64.0          30.00   180.00  34.1   \n",
       " 156             2     99.0           52.0          15.00    94.00  24.6   \n",
       " ...           ...      ...            ...            ...      ...   ...   \n",
       " 1558            6    154.0           74.0          32.00   193.00  29.3   \n",
       " 1608            9    165.0           88.0          29.34   153.74  30.4   \n",
       " 493             4    125.0           70.0          18.00   122.00  28.9   \n",
       " 527             3    116.0           74.0          15.00   105.00  26.3   \n",
       " 1192            4     95.0           60.0          32.00   153.74  35.4   \n",
       " \n",
       "       DiabetesPedigreeFunction  Age  \n",
       " 333                      0.137   44  \n",
       " 721                      0.289   21  \n",
       " 1352                     0.136   42  \n",
       " 1680                     0.328   38  \n",
       " 156                      0.637   21  \n",
       " ...                        ...  ...  \n",
       " 1558                     0.839   39  \n",
       " 1608                     0.302   49  \n",
       " 493                      1.144   45  \n",
       " 527                      0.107   24  \n",
       " 1192                     0.284   28  \n",
       " \n",
       " [1600 rows x 8 columns],\n",
       "       Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       " 278             5    114.0           74.0          29.34   153.74  24.9   \n",
       " 492             4     99.0           68.0          38.00   153.74  32.8   \n",
       " 1266            3     83.0           58.0          31.00    18.00  34.3   \n",
       " 557             8    110.0           76.0          29.34   153.74  27.8   \n",
       " 871             6    137.0           61.0          29.34   153.74  24.2   \n",
       " ...           ...      ...            ...            ...      ...   ...   \n",
       " 1290            3    170.0           64.0          37.00   225.00  34.5   \n",
       " 1462            9     72.0           78.0          25.00   153.74  31.6   \n",
       " 505            10     75.0           82.0          29.34   153.74  33.3   \n",
       " 786             3     99.0           80.0          11.00    64.00  19.3   \n",
       " 1674            2     94.0           68.0          18.00    76.00  26.0   \n",
       " \n",
       "       DiabetesPedigreeFunction  Age  \n",
       " 278                      0.744   57  \n",
       " 492                      0.145   33  \n",
       " 1266                     0.336   25  \n",
       " 557                      0.237   58  \n",
       " 871                      0.151   55  \n",
       " ...                        ...  ...  \n",
       " 1290                     0.356   30  \n",
       " 1462                     0.280   38  \n",
       " 505                      0.263   38  \n",
       " 786                      0.284   30  \n",
       " 1674                     0.561   21  \n",
       " \n",
       " [400 rows x 8 columns],\n",
       " 333     0\n",
       " 721     0\n",
       " 1352    0\n",
       " 1680    1\n",
       " 156     0\n",
       "        ..\n",
       " 1558    0\n",
       " 1608    1\n",
       " 493     1\n",
       " 527     0\n",
       " 1192    0\n",
       " Name: Outcome, Length: 1600, dtype: int64,\n",
       " 278     0\n",
       " 492     0\n",
       " 1266    0\n",
       " 557     0\n",
       " 871     0\n",
       "        ..\n",
       " 1290    1\n",
       " 1462    0\n",
       " 505     0\n",
       " 786     0\n",
       " 1674    0\n",
       " Name: Outcome, Length: 400, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split()\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f8519",
   "metadata": {},
   "source": [
    "## Modeling (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417adde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       " 330             8    118.0           72.0          19.00   153.74  23.1   \n",
       " 1326            4    110.0           66.0          29.34   153.74  31.9   \n",
       " 666             4    145.0           82.0          18.00   153.74  32.5   \n",
       " 1753            1    112.0           80.0          45.00   132.00  34.8   \n",
       " 1885            7    114.0           66.0          29.34   153.74  32.8   \n",
       " ...           ...      ...            ...            ...      ...   ...   \n",
       " 1714            0    125.0           68.0          29.34   153.74  24.7   \n",
       " 1478            3    129.0           64.0          29.00   115.00  26.4   \n",
       " 789             6    194.0           78.0          29.34   153.74  23.5   \n",
       " 1396            9    164.0           84.0          21.00   153.74  30.8   \n",
       " 910             0    189.0          104.0          25.00   153.74  34.3   \n",
       " \n",
       "       DiabetesPedigreeFunction  Age  \n",
       " 330                      1.476   46  \n",
       " 1326                     0.471   29  \n",
       " 666                      0.235   70  \n",
       " 1753                     0.217   24  \n",
       " 1885                     0.258   42  \n",
       " ...                        ...  ...  \n",
       " 1714                     0.206   21  \n",
       " 1478                     0.219   28  \n",
       " 789                      0.129   59  \n",
       " 1396                     0.831   32  \n",
       " 910                      0.435   41  \n",
       " \n",
       " [1280 rows x 8 columns],\n",
       "       Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       " 943             7    136.0           90.0          29.34   153.74  29.9   \n",
       " 908             1     97.0           70.0          15.00   153.74  18.2   \n",
       " 650             1     91.0           54.0          25.00   100.00  25.2   \n",
       " 1806            1    108.0           60.0          46.00   178.00  35.5   \n",
       " 1294            0    100.0           70.0          26.00    50.00  30.8   \n",
       " ...           ...      ...            ...            ...      ...   ...   \n",
       " 120             0    162.0           76.0          56.00   100.00  53.2   \n",
       " 546             5    187.0           76.0          27.00   207.00  43.6   \n",
       " 1349            9    123.0           70.0          44.00    94.00  33.1   \n",
       " 1829            3    102.0           44.0          20.00    94.00  30.8   \n",
       " 1206            6    162.0           62.0          29.34   153.74  24.3   \n",
       " \n",
       "       DiabetesPedigreeFunction  Age  \n",
       " 943                      0.210   50  \n",
       " 908                      0.147   21  \n",
       " 650                      0.234   23  \n",
       " 1806                     0.415   24  \n",
       " 1294                     0.597   21  \n",
       " ...                        ...  ...  \n",
       " 120                      0.759   25  \n",
       " 546                      1.034   53  \n",
       " 1349                     0.374   40  \n",
       " 1829                     0.400   26  \n",
       " 1206                     0.178   50  \n",
       " \n",
       " [320 rows x 8 columns],\n",
       " 330     0\n",
       " 1326    0\n",
       " 666     1\n",
       " 1753    0\n",
       " 1885    1\n",
       "        ..\n",
       " 1714    0\n",
       " 1478    1\n",
       " 789     1\n",
       " 1396    1\n",
       " 910     1\n",
       " Name: Outcome, Length: 1280, dtype: int64,\n",
       " 943     0\n",
       " 908     0\n",
       " 650     0\n",
       " 1806    0\n",
       " 1294    0\n",
       "        ..\n",
       " 120     1\n",
       " 546     1\n",
       " 1349    0\n",
       " 1829    0\n",
       " 1206    1\n",
       " Name: Outcome, Length: 320, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set from training set\n",
    "X_train2, X_val, y_train2, y_val = split2()\n",
    "X_train2, X_val, y_train2, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80dafe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jonathon\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jonathon\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "number of layers: 3\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\Jonathon\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "40/40 [==============================] - 2s 5ms/step - loss: 1.3009\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6467\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6178\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6171\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6146\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6000\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6070\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6068\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5932\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5956\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5979\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5878\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5862\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5923\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5808\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5815\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5853\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5806\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5816\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5837\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5829\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5836\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5843\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5820\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5822\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5825\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5773\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5766\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5795\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5775\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5754\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5786\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5762\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5766\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5745\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5759\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5741\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5730\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5686\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5762\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5753\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5756\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5742\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5755\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5774\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5714\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5691\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5749\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5727\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5709\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5714\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5722\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5683\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5733\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5723\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5692\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5727\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5759\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5724\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5707\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5684\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5691\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5737\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5711\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5699\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5693\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5704\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5655\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5711\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5714\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5603\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5658\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5701\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5712\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5702\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5631\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5722\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5745\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5685\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5693\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5716\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5611\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5708\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5658\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5655\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5688\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5653\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5643\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5659\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5647\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5665\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5655\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5700\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5685\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5653\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5666\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5655\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5694\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5686\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5705\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5649\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5649\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5639\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5675\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5628\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5635\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5658\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5705\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5641\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5690\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5627\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5700\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5588\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5679\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5632\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5589\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5649\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5662\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5640\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5629\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5639\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5627\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5611\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5612\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5647\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5646\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5680\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5659\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5631\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5623\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5595\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5624\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5624\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5645\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5629\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5626\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5586\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5595\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5624\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5581\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5608\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5676\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5630\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5587\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5632\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5612\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5567\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5604\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5622\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5593\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5638\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5657\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5649\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5616\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5590\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5650\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5628\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5615\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5610\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5574\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5609\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5595\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5653\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5572\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5627\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5559\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5647\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5573\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5603\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5594\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5591\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5593\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5621\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5608\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5566\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5599\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5661\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5607\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5611\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5588\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5596\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5563\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5634\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5627\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5632\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5581\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5638\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5582\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5603\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5618\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5580\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5579\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5562\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5597\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5571\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5611\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5588\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5593\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5561\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5532\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (32, 8)                   72        \n",
      "                                                                 \n",
      " layer2 (Dense)              (32, 8)                   72        \n",
      "                                                                 \n",
      " layer3 (Dense)              (32, 1)                   9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153 (612.00 Byte)\n",
      "Trainable params: 153 (612.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "1280\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "[0. 0. 0. ... 1. 1. 0.]\n",
      "training data model accuracy: 0.69296875; training data model log loss: nan\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "400\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "test data model accuracy: 0.7375; test data model log loss: nan\n"
     ]
    }
   ],
   "source": [
    "train_test_accuracies = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b33bd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.693, 0.738)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e8dbfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 3\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 0.7934\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6585\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6413\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6326\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6285\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6289\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6305\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6284\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6251\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6204\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6127\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6156\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6084\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6099\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6095\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6049\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6048\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5984\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6042\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5991\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5976\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5989\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6005\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5952\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5921\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6011\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5896\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5842\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5779\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5785\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5767\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5715\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5699\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5712\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5623\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5771\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5647\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5689\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5672\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5590\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5680\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5656\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5680\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5641\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5603\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5635\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5615\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5616\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5607\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5609\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5566\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5614\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5595\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5651\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5604\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5614\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5616\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5641\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5613\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5580\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5627\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5647\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5651\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5558\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5636\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5592\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5589\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5556\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5593\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5578\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5558\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5562\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5574\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5591\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5628\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5603\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5564\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5581\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5575\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5552\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5478\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5531\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5559\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5507\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5537\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5563\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5515\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5452\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5491\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5531\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5457\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5519\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5441\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5470\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5505\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5502\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5394\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5494\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5473\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5388\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5332\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5387\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5410\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5333\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5357\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5486\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5334\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5346\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5373\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5385\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5379\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5337\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5384\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5428\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5348\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5382\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5322\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5406\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5391\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5337\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5363\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5318\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5278\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5245\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5263\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5391\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5315\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5339\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5388\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5246\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5336\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5357\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5350\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5308\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5374\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5213\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5174\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5304\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5275\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5333\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5244\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5244\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5293\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5207\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5235\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5275\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5214\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5275\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5246\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5271\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5424\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5271\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5245\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5186\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5217\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5218\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5278\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5219\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5334\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5255\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5274\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5196\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5188\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5124\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5157\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5191\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5274\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5285\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5235\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5229\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5168\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5112\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5169\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5207\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5166\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5188\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5220\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5211\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5194\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5184\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5144\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5105\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5138\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5142\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5205\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5200\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5236\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5169\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5211\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5186\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5152\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5174\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (32, 8)                   72        \n",
      "                                                                 \n",
      " layer2 (Dense)              (32, 8)                   72        \n",
      "                                                                 \n",
      " layer3 (Dense)              (32, 1)                   9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153 (612.00 Byte)\n",
      "Trainable params: 153 (612.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "1280\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "training data model accuracy: 0.7359375; training data model log loss: nan\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "400\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "test data model accuracy: 0.7425; test data model log loss: nan\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "400\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[204,  60],\n",
       "       [ 43,  93]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = prediction()\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6667218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
